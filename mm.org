#+Title: Memory Models
#+Author: Anton Logvinenko
#+Email: anton.logvinenko@gmail.com
#+latex_header: \hypersetup{colorlinks=true,linkcolor=blue}
#+latex_header: \usepackage{parskip}
#+latex_header: \usepackage{enumitem}
#+latex_header: \setlist{nolistsep}
#+latex_header: \linespread{1.1}
#+MACRO: PB @@latex:\pagebreak@@ @@html: <br/><br/><br/><hr/><br/><br/><br/>@@ @@ascii: |||||@@
#+LATEX_HEADER: \usepackage[margin=1.00in]{geometry}
#+OPTIONS: ^:nil

* Fundamentals
** Data race, race condition
/If there’s no enforced ordering between two accesses to a single memory location from separate threads,
one or both of those accesses is not atomic, and if one or both is a write, then this is a *data race and causes undefined behavior*./

A *race condition* is a semantic error. It is a flaw that occurs in the timing or the ordering of events that leads to erroneous program behavior.

** Modification order
/The *modification order* is composed of all the writes to that object from all threads in the program, starting with the object’s initialization./

If different threads see distinct sequences of values for a single variable, you have a *data race and undefined behavior.*
All threads must agree on the modification orders of each individual object in a program, although they don’t necessarily have to agree on the relative order of operations on separate objects.

Modification order means:
 * *Once* a thread *has seen* a particular entry in the modification order
   * *subsequent reads* from that thread must return later values
   * *subsequent writes* from that thread to that object must *occur later* in the modification order
 * *A read* of an object that *follows a write* to that object in the same thread must either:
   * return the value written
   * or another value that occurs later in the modification order of that object


** The synchronizes-with relationship
/A suitably-tagged atomic write operation, W, on a variable, x, *synchronizes with* a suitably-tagged atomic read operation on x that reads the value stored by:/
 * /either that write, W,/
 * /or a subsequent atomic write operation on x by the same thread that performed the initial write, W,/
 * /or a sequence of atomic read-modify-write operations on x (such as fetch_add() or compare_exchange_weak()) by any thread,/
 * /where the value read by the first thread in the sequence is the value written by W/
   
The *synchronizes-with* relationship is something that you can get only between operations on atomic types.

Operations on a data structure (such as locking a mutex) might provide this relationship
if the data structure contains atomic types and the operations on that data structure perform the appropriate atomic operations internally,
but fundamentally it comes only from operations on atomic types.

All operations on atomic types are suitably tagged by default.

** The happens-before relationship
/Operation A *happens before* operation B if:/
 * /in a single thread, operation A is sequenced before operation B: PO is included in HB/
 * /if operation A in one thread *synchronizes with* operation B in another thread, then A *happens before* B: SW is included in HB/
 * /if operation A happens before operation B, and operation B happens before operation C, then A happens before C: HB is transitive/

* Memory ordering for atomic operations
/Six memory ordering options:/
 * /*relaxed ordering*/
  * /memory_order_relaxed/
 * /*acquire-release ordering*/
  * /memory_order_acquire/
  * /memory_order_release/
  * /memory_order_acq_rel/
  * /memory_order_consume/
 * /*sequentially consistent ordering*/
   * /memory_order_seq_cst/

** Sequentially consistent ordering
/The default ordering is named *sequentially consistent* because it implies that
the behavior of the program is consistent with a simple sequential view of the world.
If all operations on instances of atomic types are *sequentially consistent*, the behavior of a multithreaded program is *as if all these operations were
performed in some particular sequence by a single thread*./

This makes it easy to reason about the behavior of code written with atomic variables.
 * You can write down all the possible sequences of operations by different threads, eliminate
   those that are inconsistent, and verify that your code behaves as expected in the others.
 * Operations can’t be reordered; if your code has one operation
   before another in one thread, that ordering must be seen by all other threads.

#+CAPTION: Sequential consistency implies a total ordering
#+BEGIN_SRC cpp
  #include <atomic>
  #include <thread>
  #include <assert.h>
  std::atomic<bool> x,y;
  std::atomic<int> z;
  void write_x()
  {
    x.store(true,std::memory_order_seq_cst);     *(1)*
  }
  void write_y()
  {
    y.store(true,std::memory_order_seq_cst);     *(2)*
  }
  void read_x_then_y()
  {
    while (!x.load(std::memory_order_seq_cst));
    if (y.load(std::memory_order_seq_cst))        *(3)*
      ++z;
  }
  void read_y_then_x()
  {
    while (!y.load(std::memory_order_seq_cst));
    if (x.load(std::memory_order_seq_cst))        *(4)*
      ++z;
  }
  int main()
  {
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);                         *(5)*
  }
#+END_SRC

The assert *(5)* can never fire, because either the store to =x= *(1)* or the store to =y= *(2)* must happen first, even though it’s not specified which.

If the load of =y= in =read_x_then_y= *(3)* returns =false=
 * =x= was stored at that point, while =y= was not stored yet
 * i.e., the store to =x= must occur before the store to =y=
 * in which case  in =read_y_then_x= *(4)* when =y= is read as =true= in the while loop, we know that =x= was already written to: =x= is guaranteed to be read as =true= in *(4)*
 * meaning =z= can't be =0= in the end of execution *(5)*
 * or, (only) the opposite (symmetrical) scenario is possible: =y= write occurs strictly before =x=, with the same outcome: =z= can't be =0= in the end *(5)*

Note
 * Ususally it's "read sees write \to write happens-before read"
 * With SC, it's also "if a read does not see a write \to write can only be before read in the ordering"

#+CAPTION: Sequential consistency and happens-before
#+NAME:   fig:SED-HR4049
#+ATTR_HTML: :width 800px
[[./seq-cst.png]]

** Non-sequentially consistent memory orderings
/In *non-sequantially consistent* memory orderings:/
 * /There is *no single global order* of events: threads don't have to agree on the order of events/
 * /The only requirement is that all threads agree on the *modification order of each individual variable*./

Non-sequentially consistent memory orderings:
 * relaxed ordering
 * acquire-release ordering

*** Relaxed ordering
/Operations on atomic types performed with relaxed ordering:/
 * /don’t participate in *synchronizes-with* relationships/
 * /*modification order* is the only thing that is guaranteed/
   * /accesses to a single atomic variable from the same thread can’t be reordered:
     once a given thread has seen a particular value of an atomic variable, a subsequent read by that thread can’t retrieve
     an earlier value of the variable./

#+CAPTION: Relaxed operations have few ordering requirements
#+BEGIN_SRC cpp
      #include <atomic>
      #include <thread>
      #include <assert.h>
      std::atomic<bool> x,y;
      std::atomic<int> z;
      void write_x_then_y()
      {
	 x.store(true,std::memory_order_relaxed);  *(1)*
	 y.store(true,std::memory_order_relaxed);  *(2)*
      }
      void read_y_then_x()
      {
	while (!y.load(std::memory_order_relaxed));  *(3)*
	if (x.load(std::memory_order_relaxed))       *(4)*
	  ++z;
      }
      int main()
      {
	x=false;
  vmm
    y=false;
	z=0;
	std::thread a(write_x_then_y);
	std::thread b(read_y_then_x);
	a.join();
	b.join();
	assert(z.load() != 0);              *(5)*
    }
#+END_SRC

#+CAPTION: Relaxed atomics and happens-before
#+NAME:   fig:SED-HR4049
#+ATTR_HTML: :width 500px
[[./relaxed.png]]


The assert *(5)* can fire
 * We see that *(1)* is followed by *(2)* and =y= set to =true= after =x= is set to =true=
 * In *(3)* =y= will be eventually read as =true=
 * But the model is relaxed, so there is no SW relationship between the write in *(2)* and the read in *(3)*
 * Meaning there is no guarantee that the read in *(4)* will see =x= set to =true=, even if =y= was read as =true=
 
*** Acquire-release ordering
/Under this ordering model:/
 * /atomic loads are *acquire* operations (memory_order_acquire)/
 * /atomic stores are *release* operations (memory_order_release)/
 * /and atomic read-modify-write operations (such as fetch_add() or exchange()) are either *acquire, release, or both* (memory_order_acq_rel)/

/A release operation synchronizes-with an acquire operation that reads the value written./

The result in the previous example is impossible to get when using release acquire ordering.
Consider another example instead, the rework of the code from sequentially consistent section.

#+CAPTION: Acquire-release doesn’t imply a total ordering
#+BEGIN_SRC cpp
  #include <atomic>
  #include <thread>
  #include <assert.h>
  std::atomic<bool> x,y;
  std::atomic<int> z;
  void write_x()
  {
    x.store(true,std::memory_order_release);     *(1)*
  }
  void write_y()
  {
    y.store(true,std::memory_order_release);     *(2)*
  }
  void read_x_then_y()
  {
    while (!x.load(std::memory_order_acquire));
    if (y.load(std::memory_order_acquire))        *(3)*
      ++z;
  }
  void read_y_then_x()
  {
    while (!y.load(std::memory_order_acquire));
    if (x.load(std::memory_order_acquire))        *(4)*
      ++z;
  }
  int main()
  {
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);                         *(5)*
  }
#+END_SRC

There is no global order.
 * =x= set to =true= in *(1)* happens-before =false= is loaded from =y= in *(3)*
 * =y= set to =true= in *(2)*  happens-before =x= is read in *(4)*
 * but there is no global order, so we can't say that *(2)* happens-before *(3)*. i.e. it might look like =false= was not read from =y= before =y= was set to =true=: not related

#+CAPTION: Acquire release and happens-before
#+NAME:   fig:SED-HR4049
#+ATTR_HTML: :width 800px
[[./acq-rel.png]]

** Mixing memory orderings
 * Sequentially consistent operations behave like acquire-release
 * Relaxed operations are still relaxed, but participate in SW and HB relationships

* Release sequences and synchronizes-with
 * /If *the store* is tagged with memory_order_release, memory_order_acq_rel, or memory_order_seq_cst/
 * /and *the load* is tagged with memory_order_consume, memory_order_acquire, or memory_order_seq_cst/
 * /and each operation in the chain *loads the value written* by the previous operation/
   * /*Any atomic read-modify-write operation* in the chain/
   * /can have *any memory ordering* (even memory_order_relaxed)/
 * /then the chain of operations constitutes a *release sequence* and the initial store synchronizes with (for memory_order_acquire or memory_order_seq_cst) or is dependency-ordered-before (for memory_order_consume) the final load/

*Release sequence* also introduces a *synchronized-with* relationship.

#+CAPTION: Reading values from a queue with atomic operations
#+BEGIN_SRC cpp
  #include <atomic>
  #include <thread>
  std::vector<int> queue_data;
  std::atomic<int> count;
  void populate_queue()
  {
    unsigned const number_of_items=20;
    queue_data.clear();
    for (unsigned i = 0; i < number_of_items; ++i)
    {
      queue_data.push_back(i);
    }
    count.store(number_of_items,std::memory_order_release);                      *(1)*
  }

  void consume_queue_items()
  {
    while(true)
      {
	int item_index;
	if ((item_index = count.fetch_sub(1, std::memory_order_acquire)) <= 0))  *(2)*
	  {
	    wait_for_more_items();                                               *(3)*
	    continue;
	  }
	process(queue_data[item_index-1]);                                       *(4)*
      }
  }
#+END_SRC

#+CAPTION: The release sequence for the queue operations
#+NAME:   fig:SED-HR4049
#+ATTR_HTML: :width 800px
[[./release-sequence.png]]


 * Operations in both consumer threads are *atomic*
 * Which means either the 1st or the 2nd consuming thread will read the *value written by the writing thread*.
 * *If the 1st* thread reads (and atomically modifies) that value, *then the 2nd* thread will read another value.
 * *If the 2nd* thread reads a different value from what was written by the writer thread, it *won't have a SW relationship* with the writer thread.
 * Which means reading the queue_data in the 2nd thread is a *data race*.

* Fences
/These are operations that/
 * /fences enforce memory-ordering constraints without modifying any data/
 * /are typically combined with atomic operations that use the memory_order_relaxed ordering constraints, introducing SW and HB relationships that weren't present before./


#+CAPTION: Relaxed operations can be ordered with fences
#+BEGIN_SRC cpp
  #include <atomic>
  #include <thread>
  #include <assert.h>
  std::atomic<bool> x, y;
  std::atomic<int> z;
  void write_x_then_y()
  {
    x.store(true,std::memory_order_relaxed);                (1)
    std::atomic_thread_fence(std::memory_order_release);    (2)
    y.store(true,std::memory_order_relaxed);                (3)
  }
  void read_y_then_x()
  {
    while (!y.load(std::memory_order_relaxed));             (4)
    std::atomic_thread_fence(std::memory_order_acquire);    (5)
    if (x.load(std::memory_order_relaxed))                  (6)
      ++z;
  }
  int main()
  {
    x = false;
    y = false;
    z = 0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load() != 0);
  }
#+END_SRC

The example here works like this '\to' means we're building the only one possible order of executuion):
 * Read in (4) eventually sees write in (3), thus (3) \to (4)
 * (2) is a release fence, meaning stores above it aren't moved (reordered) downwards, stores below it aren't moved (reordered) upwards, thus (1) \to (2) \to (3)
 * (5) is a acquire fence, meaning loads above it aren't move (reordered) downwards, loads below it aren't moved (reordered) upwards, thus (4) \to (5) \to (6)
 * Transitively: (1) \to (2) \to (3) \to (4) \to (5) \to (6)
 
*The intuition is*:
 * store must "make everything before it visible the way *it* is visible" (transitively), so the *release* fence must be *above (before)* it
   #+BEGIN_SRC cpp
     //some other stores
     fence(memory_order_release);
     var.store(42, memory_order_relaxed);
   #+END_SRC
 * load must "make everything after it see the same way *it* sees", so *acquire* fence must be *below (after)* it
   #+BEGIN_SRC cpp
     load.store(memory_order_relaxed);
     fence(memory_order_acquire);
     //some other loads
   #+END_SRC

 *The general rule is:*
 * =atomic_thread_fence(memory_order_release)= + =store(memory_order_relaxed)= is equivalent to =store(memory_order_release)=
 * =load(memory_order_relaxed)= + =atomic_thread_fence(memory_order_acquire)= is equivalent to =load(memory_order_acquire)=
 * the *synchronization point is the fence itself*, not the relaxed operation: store(s) and loads(s) must be properly located around them (separated by them)

Particularly, *if only one side* is an acquire-release operation, and another is a relaxed operation with a fence, then the previous rule means that:
 * if an *acquire* operation *sees* the result of a *store* that takes place *after a release fence*, the fence synchronizes with that acquire operation
 * if a load that takes place before an acquire fence sees the result of a  release operation, the release operation synchronizes with the acquire fence
   
* Ordering non-atomic operations with atomics

#+CAPTION: Non-atomic operations can also be ordered with fences
#+BEGIN_SRC cpp
  #include <atomic>
  #include <thread>
  #include <assert.h>
  bool x = false;
  std::atomic<bool> y;
  std::atomic<int> z;
  void write_x_then_y()
  {
    x = true                                                (1)
    std::atomic_thread_fence(std::memory_order_release);    (2)
    y.store(true,std::memory_order_relaxed);                (3)
  }
  void read_y_then_x()
  {
    while (!y.load(std::memory_order_relaxed));             (4)
    std::atomic_thread_fence(std::memory_order_acquire);    (5)
    if (x)       f                                          (6)
      ++z;
  }
  int main()
  {
    x = false;
    y = false;
    z = 0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load() != 0);
  }
#+END_SRC


* Links
 * [[https://eel.is/c++draft/intro.races]]
 * [[https://timsong-cpp.github.io/cppwp/n4659/intro.multithread]]
 * [[https://stackoverflow.com/questions/70554277/what-is-the-significance-of-strongly-happens-before-compared-to-simply-happ]]
